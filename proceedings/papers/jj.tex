% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{Knowledge Tracing Machines: towards an unification of DKT, IRT \& PFA}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Jill-JÃªnn Vie}
%
\authorrunning{J.-J. Vie}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{RIKEN Center for Advanced Intelligence Project, Tokyo, Japan\\
\email{vie@jill-jenn.net}\\
\url{https://jilljenn.github.io}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
The goal of this tutorial is to make you compare typical baselines for predicting student performance (item response theory, performance factor analysis) on famous datasets, and replace some blocks of their architectures with deep neural networks (deep knowledge tracing, deep factorization machines). Hopefully we can understand where neural networks improve the predictions substantially, and where they do not. No knowledge of educational models is needed, an experience of Python is preferred. All code can be retrieved at \url{https://github.com/jilljenn/ktm}.

\keywords{Item response theory \and Deep knowledge tracing \and Predicting student performance.}
\end{abstract}
%
%
%
\end{document}
